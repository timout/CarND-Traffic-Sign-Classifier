{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Driving Car Engineer Nanodegree\n",
    "---\n",
    "### Deep Learning\n",
    "#### Project: Build a Traffic Sign Recognition Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests, io, os\n",
    "import random\n",
    "import pickle, zipfile\n",
    "import collections\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare env and load files \n",
    "\n",
    "data_dir = 'data'\n",
    "save_dir = 'model'\n",
    "zip_file = os.path.join(data_dir, 'traffic-signs-data.zip')\n",
    "zip_url = 'https://s3.amazonaws.com/video.udacity-data.com/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip'\n",
    "if not os.path.isfile(zip_file):   \n",
    "    print(\"Downloading {}\".format(zip_url))\n",
    "    if not os.path.exists('data'): os.mkdir(data_dir)\n",
    "    r = requests.get(zip_url, allow_redirects=True)\n",
    "    open(zip_file, 'wb').write(r.content)\n",
    "\n",
    "if not os.path.isdir(save_dir): os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "\n",
    "z = zipfile.ZipFile(zip_file)\n",
    "\n",
    "train_p = pickle.load(z.open('train.p'))\n",
    "test_p = pickle.load(z.open('test.p'))\n",
    "    \n",
    "X_train = train_p['features']\n",
    "y_train = train_p['labels']\n",
    "X_test  = test_p['features']\n",
    "y_test  = test_p['labels']\n",
    "\n",
    "# Load csv file with sign names\n",
    "sign_names = pd.read_csv('signnames.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 1D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a Basic Summary of the Data Set Using Python, Numpy and/or Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape \n",
    "\n",
    "# How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory visualization of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample sign names from dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sign_names.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show 1 picture from every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 18.0)\n",
    "\n",
    "p_cols = 5\n",
    "p_rows = (n_classes / p_cols) + 1\n",
    "\n",
    "# Plot one image for each label\n",
    "for i in range(0, n_classes):\n",
    "    sign_name = sign_names.loc[i].SignName\n",
    "    idx_class = np.where(y_train == i)[0]\n",
    "    rand_i = np.random.choice(idx_class)\n",
    "    plt.subplot(p_rows, p_cols, i + 1)\n",
    "    plt.imshow(X_train[rand_i])\n",
    "    plt.ylabel(sign_name, fontsize=200/(np.max([20, len(sign_name)])))   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def hist(sign_set):\n",
    "    plt.figure(figsize=(25,4))\n",
    "    plt.hist(sign_set, bins=n_classes)\n",
    "    plt.title(\"Number of samples per sign type\", loc='center')  \n",
    "    plt.xlabel('Sign')\n",
    "    plt.ylabel('Count')\n",
    "    plt.plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist(y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play! \n",
    "\n",
    "With the LeNet-5 solution from the lecture, you should expect a validation set accuracy of about 0.89. To meet specifications, the validation set accuracy will need to be at least 0.93. It is possible to get an even higher accuracy, but 0.93 is the minimum for a successful project submission. \n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture (is the network over or underfitting?)\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set (normalization, grayscale, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pixel values [0,1]. (images still in color)\n",
    "def normalize(img):\n",
    "    img_array = np.asarray(img)\n",
    "    normalized = (img_array - img_array.min()) / (img_array.max() - img_array.min())\n",
    "    return normalized\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split samples to validation and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_split, X_validate_split, y_train_split, y_validate_split = train_test_split(X_train, y_train, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=111, \n",
    "                                                    stratify=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training split\n",
    "hist(y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# validation split\n",
    "hist(y_validate_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Line = collections.namedtuple('Line', ['w', 'b', 'x'])\n",
    "\n",
    "X_validate_split, y_validate_split = shuffle(X_validate_split, y_validate_split)\n",
    "\n",
    "model_save_path = os.path.join(save_dir, 'traffic_classifier')\n",
    "model_meta_path = os.path.join(save_dir, 'traffic_classifier.meta')\n",
    "\n",
    "EPOCHS = 1 # 150\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "CONV_STRIDES = (1, 1, 1, 1)\n",
    "CONV_PADDING = 'VALID'\n",
    "POOL_KSIZE   = (1, 2, 2, 1)\n",
    "POOL_STRIDES = (1, 2, 2, 1)\n",
    "POOL_PADDING = 'VALID'\n",
    "\n",
    "# Hyperparameters\n",
    "MEAN = 0\n",
    "STDDEV = 0.1\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None,) + image_shape)\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#tf.add_to_collection('x', x)\n",
    "#tf.add_to_collection('y', y)\n",
    "#tf.add_to_collection('keep_prob', keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# one hot encoding for all possible classes\n",
    "one_hot_y = tf.one_hot(y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def conv2d(x, shape, mean, stddev):\n",
    "    size = shape[-1]\n",
    "    w = tf.Variable(tf.truncated_normal(shape=shape, mean = mean, stddev = stddev))\n",
    "    b = tf.Variable(tf.zeros(size))\n",
    "    conv = tf.nn.conv2d(x, w, strides=CONV_STRIDES, padding=CONV_PADDING) + b\n",
    "    conv = tf.nn.relu(conv)\n",
    "    conv = tf.nn.max_pool(conv, ksize=POOL_KSIZE, strides=POOL_STRIDES, padding=POOL_PADDING)\n",
    "    return Line(w=w, b=b, x=conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dropout(x, shape, mean, stddev):\n",
    "    size = shape[-1]\n",
    "    w  = tf.Variable(tf.truncated_normal(shape=shape, mean = mean, stddev = stddev))\n",
    "    b  = tf.Variable(tf.zeros(size))\n",
    "    fc = tf.matmul(x, w) + b\n",
    "    fc = tf.nn.relu(fc)\n",
    "    fc = tf.nn.dropout(fc, keep_prob)\n",
    "    return  Line(w=w, b=b, x=fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def matmul(x, shape, mean, stddev):\n",
    "    size = shape[-1]\n",
    "    w  = tf.Variable(tf.truncated_normal(shape=shape, mean = mean, stddev = stddev))\n",
    "    b  = tf.Variable(tf.zeros(size))\n",
    "    res = tf.matmul(x, w) + b\n",
    "    return  Line(w=w, b=b, x=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def LeNet(x):    \n",
    "    mean = MEAN\n",
    "    stddev = STDDEV\n",
    "    \n",
    "    conv1 = conv2d(x, (5, 5, 3, 32), mean, stddev)\n",
    "    conv2 = conv2d(conv1.x, (5, 5, 32, 64), mean, stddev)\n",
    "    \n",
    "    fc0 = flatten(conv2.x)\n",
    "    fc1 = dropout(fc0, (1600, 1024), mean, stddev)\n",
    "    fc2 = dropout(fc1.x, (1024,512), mean, stddev)\n",
    "    \n",
    "    logits = matmul(fc2.x, (512, 43), mean, stddev)\n",
    "    weights = [conv1.w, conv2.w, fc1.w, fc2.w, logits.w]   \n",
    "    \n",
    "    tf.add_to_collection('logits', logits.x)\n",
    "    \n",
    "    return logits.x, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validate and Test the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validation set can be used to assess how well the model is performing. A low accuracy on the training and validation\n",
    "sets imply underfitting. A high accuracy on the training set but low accuracy on the validation set implies overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logits, weights = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "\n",
    "# L2 Regularization \n",
    "regularizers = functools.reduce(lambda s,w : s + tf.nn.l2_loss(w), weights, 0.0)\n",
    "L2_strength = 1e-6 # L2 values between 1E-2 and 1E-6 have been found to produce good results. (tutorial)\n",
    "loss_operation = tf.reduce_mean(cross_entropy) + L2_strength * regularizers\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "training_operation = optimizer.minimize(loss_operation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.add_to_collection('accuracy_operation', accuracy_operation)\n",
    "\n",
    "def make_batches(x, y):\n",
    "    x_len = len(x)\n",
    "    for offset in range(0, x_len, BATCH_SIZE):\n",
    "        end = offset + BATCH_SIZE\n",
    "        batch_x = x[offset:end] \n",
    "        batch_y = y[offset:end]\n",
    "        yield batch_x, batch_y  \n",
    "\n",
    "def training(x_train, y_train):\n",
    "    sess = tf.get_default_session()\n",
    "    for batch_x, batch_y in make_batches(x_train, y_train):\n",
    "        sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "        \n",
    "def evaluate(x_data, y_data):\n",
    "    accuracy = 0\n",
    "    loss = 0\n",
    "    examples_size = len(x_data)\n",
    "    sess = tf.get_default_session()\n",
    "    for batch_x, batch_y in make_batches(x_data, y_data):\n",
    "        batch_accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})\n",
    "        batch_loss = sess.run(loss_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})\n",
    "        accuracy += (batch_accuracy * len(batch_x))\n",
    "        loss += (batch_loss * len(batch_x))\n",
    "    return accuracy / examples_size, loss / examples_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TensorFlow to automatically choose an existing and supported device to run the operations \n",
    "# in case the specified one doesn't exist,\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "# Fraction of the overall amount of memory that each visible GPU should be allocated.\n",
    "config.gpu_options.per_process_gpu_memory_fraction=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        print(\"Training...\")\n",
    "        for i in range(EPOCHS):\n",
    "            X_train_split, y_train_split = shuffle(X_train_split, y_train_split)\n",
    "            training(X_train_split, y_train_split)\n",
    "            training_accuracy, training_loss = evaluate(X_train_split, y_train_split)\n",
    "            validation_accuracy, validation_loss = evaluate(X_validate_split, y_validate_split)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(\" EPOCH {} ...\".format(i))\n",
    "                print(\"  Training Accuracy = {:.5f}\".format(training_accuracy))\n",
    "                print(\"  Validation Accuracy = {:.5f}\".format(validation_accuracy))\n",
    "                print(\"  Training Loss = {:.5f}\".format(training_loss))\n",
    "                print(\"  Validation Loss = {:.5f}\".format(validation_loss))\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        path = os.path.join(save_dir, model_save_path)\n",
    "        saver.save(sess, path)\n",
    "        print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run model on testing samples\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        loader = tf.train.import_meta_graph(model_meta_path)\n",
    "        loader.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "        X_test = normalize(X_test)\n",
    "        test_accuracy, test_loss = evaluate(X_test, y_test)\n",
    "        print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new images sign names\n",
    "misc_sign_names = pd.read_csv('miscsignnames.csv',index_col=0)\n",
    "misc_sign_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_image(filename): \n",
    "    img = mpimg.imread(filename)\n",
    "    return resize(img, (32, 32), mode='constant', anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "misc_dir = 'misc'\n",
    "\n",
    "filenames = os.listdir(misc_dir)\n",
    "misc_len = len(filenames)\n",
    "misc_cols = 3\n",
    "misc_rows = (misc_len / misc_cols) + 1\n",
    "\n",
    "for index, filename in enumerate(filenames):\n",
    "    sign_name = misc_sign_names.loc[filename].SignName\n",
    "    img = load_image(os.path.join(misc_dir, filename))\n",
    "    plt.subplot(misc_rows, misc_cols, index + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.ylabel(sign_name, fontsize=12)   \n",
    "plt.show()    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def misc_image_graph(img, filename, classes, predict_confidence):\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 1))\n",
    "\n",
    "    sub_img = fig.add_subplot(1, 2, 1)\n",
    "    sub_img.imshow(img)\n",
    "    sub_img.set_yticklabels([])\n",
    "    sub_img.set_xticklabels([])\n",
    "\n",
    "    bar_img = fig.add_subplot(1, 2, 2)\n",
    "    width = 1      \n",
    "    rect = bar_img.bar(classes, predict_confidence*100, width)\n",
    "    bar_img.set_xlim(0, n_classes + 2)\n",
    "    bar_img.set_ylim(0, 100)\n",
    "    bar_img.set_ylabel('Confidence')\n",
    "    bar_img.set_title('Scores')\n",
    "    x_tick_marks = list(map(lambda c: 'id: {}'.format(classes[c]), range(0, len(classes))))\n",
    "    bar_img.set_xticks(classes)\n",
    "    x_tick_names = bar_img.set_xticklabels(x_tick_marks)\n",
    "    plt.setp(x_tick_names, rotation=90, fontsize=8)\n",
    "    plt.show()\n",
    "    plt.close\n",
    "\n",
    "filenames = os.listdir(misc_dir)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        loader = tf.train.import_meta_graph(model_meta_path)\n",
    "        loader.restore(sess, tf.train.latest_checkpoint(save_dir))\n",
    "        logits = tf.get_collection('logits')[0]\n",
    "\n",
    "        print()\n",
    "        top_k = 5\n",
    "        for filename in filenames:\n",
    "            img = load_image(os.path.join(misc_dir, filename))\n",
    "            norm_img = normalize(img)\n",
    "            test_prediction = tf.nn.softmax(logits)\n",
    "            classification = sess.run(test_prediction, feed_dict = {x: [norm_img], keep_prob: 1.0})\n",
    "            test_class = sess.run(tf.argmax(classification, 1))\n",
    "            value, indices = sess.run(tf.nn.top_k(tf.constant(classification), k=top_k))\n",
    "\n",
    "            predict_confidence = value.squeeze()\n",
    "            indices = indices.squeeze()\n",
    "            sign_name = misc_sign_names.loc[filename].SignName\n",
    "            print('Sign Name: {} ({})'.format(sign_name, filename))\n",
    "            \n",
    "            for cl_id, confid in zip(indices, predict_confidence):\n",
    "                cl_name = sign_names.loc[cl_id].SignName\n",
    "                print(' Class_id:{0} ({1}), confidence:{2:.0%}'.format(cl_id, cl_name, confid))\n",
    "                \n",
    "            misc_image_graph(img, filename, indices, predict_confidence)\n",
    "            print()    \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy for these new images. \n",
    "#### Image 1\n",
    " filename: rs_01.jpg (Road work) was identify with confidence\n",
    "#### Image 2\n",
    " filename: rs_02.jpg (Speed limit (70km/h)) was identify with confidence\n",
    "#### Image 3\n",
    " filename: rs_03.jpg (Turn right ahead was identify with confidence\n",
    "#### Image 4\n",
    " filename: rs_04.jpeg (Yield) was identify with confidence\n",
    "#### Image 5\n",
    " filename: rs_05.jpg (Pedestrians Only) was identify with confidence\n",
    "#### Image 6\n",
    " filename: rs_06.jpg (Right-of-way at the next intersection) was identify with confidence\n",
    "#### Image 7\n",
    " filename: rs_07.jpg (Wild animals crossing) was identify with confidence\n",
    "#### Image 8\n",
    " filename: rs_08.jpg (Priority road) was identify with confidence\n",
    "#### Image 9\n",
    " filename: rs_09.jpg (Man with boat crossing) was identify with confidence\n",
    "#### Image 10\n",
    " filename: rs_10.jpeg (Drunk man crossing) was identify with confidence\n",
    "#### Image 11\n",
    " filename: rs_11.jpg (Wild animals crossing) was identify with confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
